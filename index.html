<!DOCTYPE html>
<html lang="en">

<head>

  <!-- Minima -->
  <!-- Hexo theme created by @adisaktijrs -->

  <!-- Basic Page Needs
  ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  <meta charset="utf-8">

  
  <title>Hongyao Tang&#39;s Homepage</title>
  
  <link rel="canonical" href="http://example.com/">
  
  <meta name="description" content="">
  
  
  <meta name="author" content="Hongyao Tang">
  
  <meta property="og:image" content="http://example.com/images/thumbnail.jpg">
  
  <meta property="og:site_name" content="Hongyao Tang&#39;s Homepage" />
  <meta property="og:type" content="article" />
  <meta property="og:title" content="Hongyao Tang&#39;s Homepage" />
  
  <meta property="og:description" content="">
  
  <meta property="og:url" content="http://example.com/" />

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Hongyao Tang&#39;s Homepage">
  
  <meta name="twitter:description" content="">
  
  
  <meta name="twitter:image" content="http://example.com/images/thumbnail.jpg">
  
  <meta name="twitter:url" content="http://example.com/" />

  <!-- Mobile Specific Metas
  ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Preload fonts
  ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  <link rel="preload" href="../fonts/dm-serif-display-v4-latin-regular.woff2" as="font" type="font/woff2" crossorigin>
  <link rel="preload" href="../fonts/inter-v2-latin-regular.woff2" as="font" type="font/woff2" crossorigin>

  <!-- CSS
  ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  
<link rel="stylesheet" href="/css/normalize.css">

  
<link rel="stylesheet" href="/css/skeleton.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
<link rel="stylesheet" href="/css/prism-dark.css">

  
<link rel="stylesheet" href="/css/prism-line-numbers.css">

  <!-- User css -->
  
  
<link rel="stylesheet" href="/css/user.css">

  

  <!-- Favicon
  ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  <link rel="icon" type="image/png" href="/images/my_favicon.jpg">

  <!-- Custom Theme Color Style
  ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  <style>
  a:not(.icon) {
    text-decoration-color: #0FA0CE;
    background-image: linear-gradient(
      to bottom,
      rgba(0, 0, 0, 0) 50%,
      #0FA0CE 50%
    );
  }
  blockquote {
    border-left: 8px solid #0FA0CE;
  }
  .nanobar .bar {
    background: #0FA0CE;
  }
  .button.button-primary:hover,
  button.button-primary:hover,
  input[type="submit"].button-primary:hover,
  input[type="reset"].button-primary:hover,
  input[type="button"].button-primary:hover,
  .button.button-primary:focus,
  button.button-primary:focus,
  input[type="submit"].button-primary:focus,
  input[type="reset"].button-primary:focus,
  input[type="button"].button-primary:focus {
    background-color: #0FA0CE;
    border-color: #0FA0CE;
  }
  input[type="email"]:focus,
  input[type="number"]:focus,
  input[type="search"]:focus,
  input[type="text"]:focus,
  input[type="tel"]:focus,
  input[type="url"]:focus,
  input[type="password"]:focus,
  textarea:focus,
  select:focus {
    border: 1px solid #0FA0CE;
  }
</style>

  <!-- Google Analytics (With Privacy Settings On)
  ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div class="container">
    <div class="row">
      <div>

        <div class="row">
<div class="eight columns ml-1">
  <div class="two columns" style="max-width: 50px">
    <h1 class="mt-2 mode">
      <div onclick=setDarkMode(true) id="darkBtn">üåë</div>
      <div onclick=setDarkMode(false) id="lightBtn" class=hidden>‚òÄÔ∏è</div>
      <script >
        if (localStorage.getItem('preferredTheme') == 'dark') {
          setDarkMode(true)
        }
        function setDarkMode(isDark) {
          var darkBtn = document.getElementById('darkBtn')
          var lightBtn = document.getElementById('lightBtn')
          if (isDark) {
            lightBtn.style.display = "block"
            darkBtn.style.display = "none"
            localStorage.setItem('preferredTheme', 'dark');
          } else {
            lightBtn.style.display = "none"
            darkBtn.style.display = "block"
            localStorage.removeItem('preferredTheme');
          }
          document.body.classList.toggle("darkmode");
        }
      </script>
    </h1>
  </div>

  <div class="seven columns ml-1">
    <h1 class="mt-2">
      Hongyao Tang&#39;s Homepage
    </h1>
  </div>

  <div class="seven columns ml-1">
    <p>
      <I style="color:grey"> </i>
    </p>
  </div>

  <div class="eight columns">
    <div class="row">
      <div class="nine columns left">
        <a href="/">Home</a>
        <a href="/archives" class="ml">Publications</a>
        
          
            <a href="mailto:tanghyyy@gmail.com" target="_blank" class="ml">Email</a>
          
        
      </div>
    </div>
  </div>

</div>


<div class="four columns left ml-0">
  <img src=/images/photo4.jpg alt="personal photo" width="200" height="200">
</div>

</div>

<hr />

        <div class="trans">
          <head>
<script defer src="https://cloud.umami.is/script.js" data-website-id="c18823bb-5edc-42ac-9611-3d15eb7f83e8"></script>
</head>

<h3>Personal Information</h3>
<div class="row">
  <div class="column">
    <p>Hello, I am Hongyao Tang, Ê±§ÂÆèÂûö. I am an Associate Research Fellow at <a target="_blank" rel="noopener" href="http://www.icdai.org">TJU RL Lab</a>, College of Intelligence and Computing, Tianjin University.
</p> 
    <p>Prior to this, I was a postdoctoral researcher with Professor <a target="_blank" rel="noopener" href="https://neo-x.github.io/">Glen Berseth</a>, in <a target="_blank" rel="noopener" href="https://montrealrobotics.ca/">Robotics and Embodied AI Lab (REAL)</a> at the Mila and Universit√© de Montr√©al. I obtained my Ph.D. (Master's and Bachelor's Degree as well) in
    <a target="_blank" rel="noopener" href="http://www.icdai.org/index.html">Deep Reinforcement Learning (DRL) Lab</a>, Tianjin University advised by Professor <a target="_blank" rel="noopener" href="http://www.icdai.org/jianye.html">Jianye Hao</a>, Zhaopeng Meng, and Li Wang.
    </p>
    <p>My research interests lie in unveiling the learning dynamics of Deep Reinforcement Learning (DRL) and realizing new approaches/paradigms for efficient, performant and generalizable agents</b>. <b>My current research focus is on Learning under Nonstationarity (i.e., one intriguing nature of RL)</b>, and concretely, <b>I study Continual RL and RL problems in LLMs and embodied intelligence</b>. I am also interested in Meta RL, MARL, Offline RL, Machine Unlearning, etc.
    </p>
    <p>I have experience in applying DRL in practical problems like Electronic Design Automation (EDA), Drug Discovery, Online Games and etc. I am very willing to contribute to addressing real-world problems.
    </p>
  </div>
</div>

<hr />

<h3>‚ö°Ô∏è Highlight</h3>

<p style="color:black">For prospective students (master, ph.d., RA, etc.) and collaboration partners, please contact me via my email (above) or contact via the homepage of <a target="_blank" rel="noopener" href="http://www.icdai.org">TJU RL Lab</a>.</p>


<hr />

<h3>üåü News</h3>


<div class="row">

  <div class="two columns left lit">
    <p class="bottom">2026.01</p>
  </div>
  <div class="nine columns right">
    <p class="bottom"><b>Three papers accepted to ICLR 2026</b> on off-policy RFT for LLM Reasoning, plasticity loss in RL and reinforced embodied reasoning for general robotic manipulation!</p>
  </div>
</div>

<div class="row">

  <div class="two columns left lit">
    <p class="bottom">2025.12</p>
  </div>
  <div class="nine columns right">
    <p class="bottom"><b>One paper accepted to AAMAS 2026 (Full Paper, Oral)</b> on a unified theory of policy abstraction and representation!</p>
  </div>
</div>

<div class="row">

  <div class="two columns left lit">
    <p class="bottom">2025.09</p>
  </div>
  <div class="nine columns right">
    <p class="bottom"><b>We released <a target="_blank" rel="noopener" href="https://embodied-arena.com/">Embodied Arena</a> ü§ñ, a comprehensive, unified, and evolving evaluation platform for Embodied AI.</b> Feel free to check the platform and our <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.15273">tech report</a> out!</p>
  </div>
</div>

<div class="row">

  <div class="two columns left lit">
    <p class="bottom">2025.09</p>
  </div>
  <div class="nine columns right">
    <p class="bottom"><b>Four papers accepted to NeurIPS 2025</b> on LLM-driven reward function design, multi-objective RL, offline RL, and EDA floorplanning!</p>
  </div>
</div>



<div class="row">

  <div class="two columns left lit">
    <p class="bottom">2025.05</p>
  </div>
  <div class="nine columns right">
    <p class="bottom"><b>One paper accepted to RLC 2025</b> on efficient cross-morphology adaptation!</p>
  </div>
</div>


<div class="row">

  <div class="two columns left lit">
    <p class="bottom">2025.05</p>
  </div>
  <div class="nine columns right">
    <p class="bottom"><b>Two papers accepted to ICML 2025</b> on continual RL and LLM-driven reward design!</p>
  </div>
</div>

<div class="row">

  <div class="two columns left lit">
    <p class="bottom">2025.01</p>
  </div>
  <div class="nine columns right">
    <p class="bottom"><b>Excited to join TJU RL Lab as an Associate Research Fellow!</b></p>
  </div>
</div>

<div class="row">

  <div class="two columns left lit">
    <p class="bottom">2024.09</p>
  </div>
  <div class="nine columns right">
    <p class="bottom"><b>Two papers accepted to NeurIPS 2024</b> on network churn and learning dynamics of DRL!</p>
  </div>
</div>





<div class="row">

  <div class="two columns left lit">
    <p class="bottom">2023.11</p>
  </div>
  <div class="nine columns right">
    <p class="bottom"><b>Excited to join Mila/UdeM as a Postdoctoral Research Fellow!</b> It is a great honor to work with Prof. <a target="_blank" rel="noopener" href="https://neo-x.github.io/">Glen Berseth</a>.</p>
  </div>
</div>


<div class="row">

  <div class="two columns left lit">
    <p class="bottom">2023.06</p>
  </div>
  <div class="nine columns right">
    <p class="bottom"><b>Got my Ph.D. at Tianjin University!</b> Grateful to Prof. <a target="_blank" rel="noopener" href="http://www.icdai.org/jianye.html">Jianye Hao</a> and Prof. Zhaopeng Meng.</p>
  </div>
</div>

<hr />

<h3>üõ£ Education & Work Experiences</h3>


<div class="row">
  <div class="three columns left lit">
    <p class="bottom">2025.01 - Present</p>
  </div>
  <div class="nine columns right">
    <p class="bottom"><b>Associate Research Fellow</b>, TJU RL Lab, College of Intelligence and Computing, Tianjin University</p>
  </div>
</div>

<div class="row">
  <div class="three columns left lit">
    <p class="bottom">2023.11 - 2024.12</p>
  </div>
  <div class="nine columns right">
    <p class="bottom"><b>Postdoctoral Research Fellow</b>, Robotics and Embodied AI Lab (REAL), Mila/UdeM (work with <u>Glen Berseth</u>, and co-author with <u>Johan Obando-Ceron</u>, <u>Pablo Samuel Castro</u>, and <u>Aaron Courville</u>)</p>
  </div>
</div>

<div class="row">

  <div class="three columns left lit">
    <p class="bottom">2019.09 - 2023.06</p>
  </div>
  <div class="nine columns right">
    <p class="bottom"><b>Ph.D.</b>, College of Intelligence and Computing, Tianjin University (advised by <u>Jianye Hao</u> and <u>Zhaopeng Meng</u>)</p>
  </div>
</div>


<div class="row">

  <div class="three columns left lit">
    <p class="bottom">2020.05 - 2023.04</p>
  </div>
  <div class="nine columns right">
    <p class="bottom">DRL Researcher (Intern), Noah's Ark Lab, Huawei (work with <u>Chen Chen</u> and <u>Zhentao Tang</u>)</p>
  </div>
</div>

<div class="row">

  <div class="three columns left lit">
    <p class="bottom">2019.09 - 2020.04</p>
  </div>
  <div class="nine columns right">
    <p class="bottom">AI Researcher (Intern), Quantum Lab, Tencent (work with <u>Guangyong Chen</u>)</p>
  </div>
</div>



<div class="row">

  <div class="three columns left lit">
    <p class="bottom">2018.07 - 2018.10</p>
  </div>
  <div class="nine columns right">
    <p class="bottom">DRL Researcher (Intern), Fuxi AI Lab, NetEase (work with <u>Tangjie Lv</u>)</p>
  </div>
</div>

<div class="row">

  <div class="three columns left lit">
    <p class="bottom">2017.09 - 2019.07</p>
  </div>
  <div class="nine columns right">
    <p class="bottom"><b>Master</b>, College of Intelligence and Computing, Tianjin University (advised by <u>Jianye Hao</u> and <u>Li Wang</u>)</p>
  </div>
</div>
<div class="row">

  <div class="three columns left lit">
    <p class="bottom">2013.09 - 2017.07</p>
  </div>
  <div class="nine columns right">
    <p class="bottom"><b>Bachelor</b>, School of Software Engineering, Tianjin University</p>
  </div>
</div>

<hr />


<h3>üß† Selected Publications & Preprints</h3>

<p style="color:grey">PS: Authors with equal contribution are marked by *. Corresponding authors are marked by üìÆ.</p>


<div class="row">
  <p><b>Squeeze the Soaked Sponge: Efficient Off-policy Reinforcement Finetuning for Large Language Model
  </b><br />
  Jing Liang*, Jinyi Liu*, Yi Ma*, <u>Hongyao Tang</u>üìÆ, Yan Zheng, Shuyue Hu, Lei Bai, Jianye Hao<br />
  <i>ICLR 2026</I>
  | [<a target="_blank" rel="noopener" href="https://openreview.net/pdf?id=quBjNSJMrC">Paper</a>] [<a target="_blank" rel="noopener" href="https://anitaleungxx.github.io/ReMix/">Project Page</a>]
  </p>
</div>

<div class="row">
  <p><b>The Rank and Gradient Lost in Non-stationarity: Sample Weight Decay for Mitigating Plasticity Loss in Reinforcement Learning
  </b><br />
  Zihao Wu, <u>Hongyao Tang</u>üìÆ, Yi Ma, Jiashun Liu, Yan Zheng, Jianye Hao<br />
  <i>ICLR 2026</I>
  | [<a target="_blank" rel="noopener" href="https://openreview.net/forum?id=5DpzzTPnJZ">Paper</a>] 
  </p>
</div>

<div class="row">
  <p><b>Embodied-R1: Reinforced Embodied Reasoning for General Robotic Manipulation
  </b><br />
  Yifu Yuan, Haiqin Cui, Yaoting Huang, Yibin Chen, Fei Ni, Zibin Dong, Pengyi Li, Yan Zheng, <u>Hongyao Tang</u>, Jianye Hao<br />
  <i>ICLR 2026</I>
  | [<a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.13998">Paper</a>] [<a target="_blank" rel="noopener" href="https://embodied-r1.github.io/">Project Page</a>]
  </p>
</div>


<div class="row">
<p><b>Towards A Unified Policy Abstraction Theory and Representation Learning Approach in Markov Decision Processes</b><br />
Min Zhang, <u>Hongyao Tang</u>üìÆ, Jianye Hao, Yan Zheng<br />
<i>AAMAS 2026 (Full Paper, Oral)</I>
 | [<a href="">Paper</a>]
</p>
</div>


<div class="row">
<p><b>Embodied Arena: A Comprehensive, Unified, and Evolving Evaluation Platform for Embodied AI</b><br />
Fei Ni, Min Zhang, Pengyi Li, Yifu Yuan, Lingfeng Zhang, Yuecheng Liu, Peilong Han, Longxin Kou, Shaojin Ma, Jinbin Qiao, David Gamaliel Arcos Bravo, Yuening Wang, Xiao Hu, Zhanguang Zhang, Xianze Yao, Yutong Li, Zhao Zhang, Ying Wen, Ying-Cong Chen, Xiaodan Liang, Liang Lin, Bin He, Haitham Bou-Ammar, He Wang, Huazhe Xu, Jiankang Deng, Shan Luo, Shuqiang Jiang, Wei Pan, Yang Gao, Stefanos Zafeiriou, Jan Peters, Yuzheng Zhuang, Yingxue Zhang, Yan Zheng, <u>Hongyao Tang</u>, Jianye Hao<br />
<i>arXiv 2025</I>
| [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.15273">Paper</a>]
</p>
</div>

<div class="row">
<p><b>LaRes: Evolutionary Reinforcement Learning with LLM-based Adaptive Reward Search</b><br />
Pengyi Li, Jianye Hao, <u>Hongyao Tang</u>, Jinbin Qiao, Yan Zheng<br />
<i>NeurIPS 2025</I>
| [<a href="">Paper</a>]
</p>
</div>

<div class="row">
<p><b>COLA: Towards Efficient Multi-Objective Reinforcement Learning with Conflict Objective Regularization in Latent Space</b><br />
Pengyi Li, Jianye Hao, Yifu Yuan, <u>Hongyao Tang</u>üìÆ, Zibin Dong, Yan Zheng<br />
<i>NeurIPS 2025</I>
| [<a href="">Paper</a>]
</p>
</div>

<div class="row">
<p><b>Scaling DRL for Decision Making: A Survey on Data, Network, and Training Budget Strategies
</b><br />
Yi Ma*, <u>Hongyao Tang</u>*, Chenjun Xiao, Yaodong Yang, Wei Wei, Jianye Hao, Jiye Liang<br />
<i>arXiv preprint 2025</I>
| [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2508.03194">Paper</a>]
</p>
</div>



<div class="row">
<p><b>Efficient Morphology-Aware Policy Transfer to New Embodiments
</b><br />
Michael Przystupa, <u>Hongyao Tang</u>, Glen Berseth, Mariano Phielipp, Santiago Miret, Martin J√§gersand, Matthew E. Taylor<br />
<i>RLC 2025</I>
| [<a target="_blank" rel="noopener" href="https://openreview.net/attachment?id=sX47KXdPZj&name=pdf">Paper</a>]
</p>
</div>


<div class="row">
<p><b>Mitigating Plasticity Loss in Continual Reinforcement Learning by Reducing Churn
</b><br />
<u>Hongyao Tang</u>üìÆ, Johan Obando-Ceron, Pablo Samuel Castro, Aaron Courville, Glen Berseth<br />
<i>ICML 2025</I>
| [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.00592">Paper</a>]
[<a target="_blank" rel="noopener" href="https://github.com/bluecontra/C-CHAIN">Code</a>]
</p>
</div>



<div class="row">
<p><b>Can We Optimize Deep RL Policy Weights as Trajectory Modeling?
</b><br />
<u>Hongyao Tang</u><br />
<i>ICLR 2025 Workshop on Weight Space Learning</I>
| [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2503.04074">Paper</a>]
</p>
</div>

<div class="row">
<p><b>Improving Deep Reinforcement Learning by Reducing the Chain Effect of Value and Policy Churn</b><br />
<u>Hongyao Tang</u>, Glen Berseth<br />
<i>NeurIPS 2024</I>
 | [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2409.04792">Paper</a>]
[<a target="_blank" rel="noopener" href="https://github.com/bluecontra/CHAIN">Code</a>]
</p>
</div>


<div class="row">
<p><b>The Ladder in Chaos: Improving Policy Learning by Harnessing the Parameter Evolving Path in A Low-dimensional Space</b><br />
<u>Hongyao Tang</u>, Min Zhang, Chen Chen, Jianye Hao <br />
<i>NeurIPS 2024</I>
 | [<a target="_blank" rel="noopener" href="https://openreview.net/pdf?id=3vHfwL2stG">Paper</a>]
</p>
</div>


<div class="row">
<p><b>EvoRainbow: Combining Improvements in Evolutionary Reinforcement Learning for Policy Search</b><br />
Pengyi Li, Jianye Hao, <u>Hongyao Tang</u>, Xian Fu, Yan Zheng<br />
<i>ICML 2024</I>
 | [<a target="_blank" rel="noopener" href="https://openreview.net/pdf?id=75Hes6Zse4">Paper</a>]
[<a target="_blank" rel="noopener" href="https://github.com/yeshenpy/EvoRainbow">Code</a>]
</p>
</div>




<div class="row">
<p><b>Reining Generalization in Offline Reinforcement Learning via Representation Distinction</b><br />
Yi Ma, <u>Hongyao Tang</u>üìÆ, Dong Li, Zhaopeng Meng<br />
<i>NeurIPS 2023</I>
 | [<a target="_blank" rel="noopener" href="https://openreview.net/forum?id=mVywRIDNIl">Paper</a>]
</p>
</div>





<div class="row">
<p><b>HyAR: Addressing Discrete-Continuous Action Reinforcement Learning via Hybrid Action Representation</b><br />
Boyan Li*, <u>Hongyao Tang</u>*, Yan Zheng, Jianye Hao, Pengyi Li, Zhen Wang, Zhaopeng Meng, Li Wang<br />
<i>ICLR 2022</i>
 | [<a target="_blank" rel="noopener" href="https://openreview.net/pdf?id=64trBbOhdGU">Paper</a>]
[<a target="_blank" rel="noopener" href="https://github.com/TJU-DRL-LAB/self-supervised-rl/tree/main/RL_with_Action_Representation/HyAR">Code</a>]
</p>
</div>

<div class="row">
<p><b>What about Inputting Policy in Value Function: Policy Representation and Policy-Extended Value Function Approximator</b><br />
<u>Hongyao Tang</u>, Zhaopeng Meng, Jianye Hao, Chen Chen, Daniel Graves, Dong Li, Changmin Yu, Hangyu Mao, Wulong Liu, Yaodong Yang, Wenyuan Tao, Li Wang<br />
<i>AAAI 2022 Oral Presentation (< 5%)</i>
 | [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2010.09536.pdf">Paper</a>]
[<a target="_blank" rel="noopener" href="https://github.com/TJU-DRL-LAB/self-supervised-rl/tree/main/RL_with_Policy_Representation/Policy-based_RL_with_PeVFA/PPO-PeVFA">Code</a>]

</p>
</div>









<h4> <a href="/archives">More Publications</a></h4>



<hr />






<h3>Academic Service</h3>
<h4>Reviewer</h4>
<div class="row">
  <div class="three columns left lit">
    <p class="bottom">RLC</p>
  </div>
  <div class="nine columns right">
    <p class="bottom">2024, 2025</p>
  </div>
</div>

<div class="row">
  <div class="three columns left lit">
    <p class="bottom">NeurIPS</p>
  </div>
  <div class="nine columns right">
    <p class="bottom">2021 - 2025 <I>(Top Reviewer Award at NeurIPS 2022)</I></p>
  </div>
</div>

<div class="row">
  <div class="three columns left lit">
    <p class="bottom">ICLR</p>
  </div>
  <div class="nine columns right">
    <p class="bottom">2022 - 2026 <I>(Highlighted Reviewer Award at ICLR 2022)</I></p>
  </div>
</div>

<div class="row">
  <div class="three columns left lit">
    <p class="bottom">ICML</p>
  </div>
  <div class="nine columns right">
    <p class="bottom">2021 - 2026</p>
  </div>
</div>

<div class="row">
  <div class="three columns left lit">
    <p class="bottom">AAAI</p>
  </div>
  <div class="nine columns right">
    <p class="bottom">2021 - 2025</p>
  </div>
</div>

<div class="row">
  <div class="three columns left lit">
    <p class="bottom">IJCAI</p>
  </div>
  <div class="nine columns right">
    <p class="bottom">2021 - 2024</p>
  </div>
</div>

<div class="row">
  <div class="three columns left lit">
    <p class="bottom">AAMAS</p>
  </div>
  <div class="nine columns right">
    <p class="bottom">2021 - 2024</p>
  </div>
</div>

<div class="row">
  <div class="nine columns left lit">
    <p class="bottom">Nature Communications</p>
  </div>
</div>

<div class="row">
  <div class="nine columns left lit">
    <p class="bottom">Transactions on Machine Learning Research (TMLR)</p>
  </div>
</div>

<div class="row">
  <div class="nine columns left lit">
    <p class="bottom">IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</p>
  </div>
</div>



<hr />



<h3>Invited Talks</h3>


<div class="row">

  <div class="three columns left lit">
    <p class="bottom">2025.03</p>
  </div>
  <div class="nine columns right">
    <p class="bottom"><b>RL in the Era of Large Models</b><br />
    <i>2025 IEEE International Conference on Industrial Technology</i><br />
  </div>
</div>

<div class="row">

  <div class="three columns left lit">
    <p class="bottom">2024.10</p>
  </div>
  <div class="nine columns right">
    <p class="bottom"><b>Where is the Road to Flawless RL? ‚Äî Unsolved Problems and New Approaches</b><br />
    <i>Google DeepMind, Discovery Team London (Remote)</i><br />
  </div>
</div>


<div class="row">

  <div class="three columns left lit">
    <p class="bottom">2023.05</p>
  </div>
  <div class="nine columns right">
    <p class="bottom"><b>A Tale of Representations in Deep Reinforcement Learning</b><br />
    <i>Robotics and Embodied AI Lab (REAL), the Universit√© de Montr√©al</i><br />
  </div>
</div>




<div class="row">

  <div class="three columns left lit">
    <p class="bottom">2022.07</p>
  </div>
  <div class="nine columns right">
    <p class="bottom"><b>Towards Understanding The Learning Dynamics of Deep Reinforcement Learning</b><br />
    <i>Huawei Noah‚Äôs Ark Lab, Decision-making and Reasoning Group (during internship)</i></p>
  </div>
</div>
<div class="row">

  <div class="three columns left lit">
    <p class="bottom">2021.10</p>
  </div>
  <div class="nine columns right">
    <p class="bottom"><b>Self-supervised Reinforcement Learning ‚Äî A Perspective of Representation</b><br />
    <i>2021 TJU RL Summer Seminar</i></p>
  </div>
</div>



<div class="row">

  <div class="three columns left lit">
    <p class="bottom">2020.11</p>
  </div>
  <div class="nine columns right">
    <p class="bottom"><b>State Abstraction and State Representation Learning in Reinforcement Learning</b><br />
    <i>Huawei Noah‚Äôs Ark Lab, Decision-making and Reasoning Group (during internship)</i></p>
  </div>
</div>



<div class="row">

  <div class="three columns left lit">
    <p class="bottom">2019.08</p>
  </div>
  <div class="nine columns right">
    <p class="bottom"><b>Bias and Variance in Deep Reinforcement Learning</b><br />
    <i>2019 TJU RL Summer Seminar</i></p>
  </div>
</div>





<hr />






          <div class="row mt-2">
  
    <div class="eight columns">
      <p id="madewith">Updated by Hongyao Tang, Sep 2025.
    </div>

    <!-- Sepcial thanks to https://simpleicons.org/ for the icons -->
    <div class="four columns mb-3 posisi" >
      
      <a class="ml-0 footer-link icon" href="https://github.com/bluecontra" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="GitHub">
        <svg class="github svg-hov" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
      </a>
      

      

      
      <a class="ml-0 footer-link icon" href="https://twitter.com/tanghyyy" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="Twitter">
        <svg class="twitter svg-hov" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Twitter</title><path d="M23.954 4.569c-.885.389-1.83.654-2.825.775 1.014-.611 1.794-1.574 2.163-2.723-.951.555-2.005.959-3.127 1.184-.896-.959-2.173-1.559-3.591-1.559-2.717 0-4.92 2.203-4.92 4.917 0 .39.045.765.127 1.124C7.691 8.094 4.066 6.13 1.64 3.161c-.427.722-.666 1.561-.666 2.475 0 1.71.87 3.213 2.188 4.096-.807-.026-1.566-.248-2.228-.616v.061c0 2.385 1.693 4.374 3.946 4.827-.413.111-.849.171-1.296.171-.314 0-.615-.03-.916-.086.631 1.953 2.445 3.377 4.604 3.417-1.68 1.319-3.809 2.105-6.102 2.105-.39 0-.779-.023-1.17-.067 2.189 1.394 4.768 2.209 7.557 2.209 9.054 0 13.999-7.496 13.999-13.986 0-.209 0-.42-.015-.63.961-.689 1.8-1.56 2.46-2.548l-.047-.02z"/></svg>
      </a>
      

      

    </div>
  
</div>

        </div>
      </div>

    </div>

  </div>
  <script src="/js/nanobar.min.js"></script>
  <script>
    var options = {
      classname: 'nanobar',
      id: 'myNanobar'
    };
    var nanobar = new Nanobar(options);
    nanobar.go(30);
    nanobar.go(76);
    nanobar.go(100);
  </script>

</body>

</html>
