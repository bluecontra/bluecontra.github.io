<!DOCTYPE html>
<html lang="en">

<head>

  <!-- Minima -->
  <!-- Hexo theme created by @adisaktijrs -->

  <!-- Basic Page Needs
  ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  <meta charset="utf-8">

  
  <title>All Posts - Hongyao Tang</title>
  
  <link rel="canonical" href="http://example.com/archives/2022/">
  
  <meta name="description" content="">
  
  
  <meta name="author" content="Hongyao Tang">
  
  <meta property="og:image" content="http://example.com/images/thumbnail.jpg">
  
  <meta property="og:site_name" content="Hongyao Tang&#39;s Homepage" />
  <meta property="og:type" content="article" />
  <meta property="og:title" content="All Posts - Hongyao Tang" />
  
  <meta property="og:description" content="">
  
  <meta property="og:url" content="http://example.com/archives/2022/" />

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="All Posts - Hongyao Tang">
  
  <meta name="twitter:description" content="">
  
  
  <meta name="twitter:image" content="http://example.com/images/thumbnail.jpg">
  
  <meta name="twitter:url" content="http://example.com/archives/2022/" />

  <!-- Mobile Specific Metas
  ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Preload fonts
  ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  <link rel="preload" href="../fonts/dm-serif-display-v4-latin-regular.woff2" as="font" type="font/woff2" crossorigin>
  <link rel="preload" href="../fonts/inter-v2-latin-regular.woff2" as="font" type="font/woff2" crossorigin>

  <!-- CSS
  ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  
<link rel="stylesheet" href="/css/normalize.css">

  
<link rel="stylesheet" href="/css/skeleton.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
<link rel="stylesheet" href="/css/prism-dark.css">

  
<link rel="stylesheet" href="/css/prism-line-numbers.css">

  <!-- User css -->
  
  
<link rel="stylesheet" href="/css/user.css">

  

  <!-- Favicon
  ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  <link rel="icon" type="image/png" href="/images/my_favicon.jpg">

  <!-- Custom Theme Color Style
  ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  <style>
  a:not(.icon) {
    text-decoration-color: #0FA0CE;
    background-image: linear-gradient(
      to bottom,
      rgba(0, 0, 0, 0) 50%,
      #0FA0CE 50%
    );
  }
  blockquote {
    border-left: 8px solid #0FA0CE;
  }
  .nanobar .bar {
    background: #0FA0CE;
  }
  .button.button-primary:hover,
  button.button-primary:hover,
  input[type="submit"].button-primary:hover,
  input[type="reset"].button-primary:hover,
  input[type="button"].button-primary:hover,
  .button.button-primary:focus,
  button.button-primary:focus,
  input[type="submit"].button-primary:focus,
  input[type="reset"].button-primary:focus,
  input[type="button"].button-primary:focus {
    background-color: #0FA0CE;
    border-color: #0FA0CE;
  }
  input[type="email"]:focus,
  input[type="number"]:focus,
  input[type="search"]:focus,
  input[type="text"]:focus,
  input[type="tel"]:focus,
  input[type="url"]:focus,
  input[type="password"]:focus,
  textarea:focus,
  select:focus {
    border: 1px solid #0FA0CE;
  }
</style>

  <!-- Google Analytics (With Privacy Settings On)
  ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div class="container">
    <div class="row">
      <div>

        <div class="row">
<div class="nine columns ml-1">
  <div class="two columns" style="max-width: 50px">
    <h1 class="mt-2 mode">
      <div onclick=setDarkMode(true) id="darkBtn">üåë</div>
      <div onclick=setDarkMode(false) id="lightBtn" class=hidden>‚òÄÔ∏è</div>
      <script >
        if (localStorage.getItem('preferredTheme') == 'dark') {
          setDarkMode(true)
        }
        function setDarkMode(isDark) {
          var darkBtn = document.getElementById('darkBtn')
          var lightBtn = document.getElementById('lightBtn')
          if (isDark) {
            lightBtn.style.display = "block"
            darkBtn.style.display = "none"
            localStorage.setItem('preferredTheme', 'dark');
          } else {
            lightBtn.style.display = "none"
            darkBtn.style.display = "block"
            localStorage.removeItem('preferredTheme');
          }
          document.body.classList.toggle("darkmode");
        }
      </script>
    </h1>
  </div>

  <div class="seven columns ml-1">
    <h1 class="mt-2">
      Hongyao Tang&#39;s Homepage
    </h1>
  </div>

  <div class="seven columns ml-1">
    <p>
      <I style="color:grey"> </i>
    </p>
  </div>

  <div class="nine columns">
    <div class="row">
      <div class="nine columns left">
        <a href="/">Home</a>
        <a href="/archives" class="ml">Publications</a>
        
          
            <a href="mailto:tanghyyy@gmail.com" target="_blank" class="ml">Email</a>
          
        
      </div>
    </div>
  </div>

</div>


<div class="three columns left ml-2">
  <img src=/images/photo2.jpg alt="personal photo" width="134" height="180">
</div>

</div>

<hr />

        <div class="trans">
          
<h2>Selected Publications & Preprints</h2>

<p style="color:grey">PS: Authors with equal contribution are marked by *.</p>


<h3 style="color:blue">2024</h3>



<div class="row">
<p>[37] <b>Dual Ensembled Multiagent Q-Learning with Hypernet Regularizer</b><br />
Yaodong Yang, Guangyong Chen, <u>Hongyao Tang</u>, Furui Liu, Danruo DENG, Pheng-Ann Heng<br />
<i>AAMAS 2025</I>
 | [<a target="_blank" rel="noopener" href="https://openreview.net/pdf?id=6bAkCauS3N">Paper</a>]
</p>
</div>



<div class="row">
<p>[36] <b>Improving Deep Reinforcement Learning by Reducing the Chain Effect of Value and Policy Churn</b><br />
<u>Hongyao Tang</u>, Glen Berseth<br />
<i>NeurIPS 2024</I>
 | [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2409.04792">Paper</a>]
</p>
</div>

<div class="row">
<p>[35] <b>The Ladder in Chaos: Improving Policy Learning by Harnessing the Parameter Evolving Path in A Low-dimensional Space</b><br />
<u>Hongyao Tang</u>, Min Zhang, Chen Chen, Jianye Hao <br />
<i>NeurIPS 2024</I>
 | [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2303.01391.pdf">Paper</a>]
</p>
</div>


<div class="row">
<p>[34] <b>Minimally Invasive Morphology Adaptation via Parameter Efficient Fine-Tuning</b><br />
Michael Przystupa, <u>Hongyao Tang</u>, Mariano Phielipp, Santiago Miret, Martin J√§gersand, Glen Berseth<br />
<i>CoRL 2024 Workshop on MAPoDeL</I>
 | [<a target="_blank" rel="noopener" href="https://openreview.net/forum?id=kvkC88H3Oi">Paper</a>]
</p>
</div>

<div class="row">
<p>[33] <b>Self-Supervised Bisimulation Action Chunk Representation for Efficient RL</b><br />
Lei Shi, Jianye Hao, <u>Hongyao Tang</u>, Zibin Dong, Yan Zheng <br />
<i>NeurIPS 2024 Workshop on Self-Supervised Learning - Theory and Practice/SafeGenAi</I>
 | [<a target="_blank" rel="noopener" href="https://openreview.net/forum?id=hNnATj3Ib3">Paper</a>]
</p>
</div>



<div class="row">
<p>[31] <b>HuLE-Nav: Human-Like Exploration for Zero-Shot Object Navigation via Vision-Language Models</b><br />
Peilong Han, Min Zhang, Jianye Hao, <u>Hongyao Tang</u>, Yan Zheng<br />
<i>NeurIPS 2024 Workshop on Behavioral ML</I>
 | [<a target="_blank" rel="noopener" href="https://openreview.net/forum?id=akVkINWMxg">Paper</a>]
</p>
</div>


<div class="row">
<p>[31] <b>Learning Robust Representations for Transfer in Reinforcement Learning</b><br />
Faisal Mohamed, Roger Creus Castanyer, <u>Hongyao Tang</u>, Zahra Sheikhbahaee, Glen Berseth<br />
<i>NeurIPS 2024 Workshop on FITML</I>
 | [<a target="_blank" rel="noopener" href="https://openreview.net/forum?id=tHa7MhPCdg">Paper</a>]
</p>
</div>


<div class="row">
<p>[30] <b>MFE-ETP: A Comprehensive Evaluation Benchmark for Multi-modal Foundation Models on Embodied Task Planning</b><br />
Min Zhang, Jianye Hao, Xian Fu, Peilong Han, Hao Zhang, Lei Shi, <u>Hongyao Tang</u>, Yan Zheng<br />
<i>arXiv preprint 2024</I>
 | [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.05047">Paper</a>]
</p>
</div>


<div class="row">
<p>[29] <b>What can VLMs Do for Zero-shot Embodied Task Planning?</b><br />
Xian Fu, Min Zhang, Jianye Hao, Peilong Han, Hao Zhang, Lei Shi, <u>Hongyao Tang</u><br />
<i>ICML 2024 Workshop on LLMs and Congition</I>
 | [<a target="_blank" rel="noopener" href="https://openreview.net/pdf?id=OE5WKiNPyx">Paper</a>]
</p>
</div>


<div class="row">
<p>[28] <b>EvoRainbow: Combining Improvements in Evolutionary Reinforcement Learning for Policy Search</b><br />
Pengyi Li, Jianye Hao, <u>Hongyao Tang</u>, Xian Fu, Yan Zheng<br />
<i>ICML 2024</I>
 | [<a target="_blank" rel="noopener" href="https://openreview.net/pdf?id=75Hes6Zse4">Paper</a>]
</p>
</div>


<div class="row">
<p>[27] <b>Value-Evolutionary-Based Reinforcement Learning</b><br />
Pengyi Li, Jianye Hao, <u>Hongyao Tang</u>, Yan Zheng, Fazl Barez<br />
<i>ICML 2024</I>
 | [<a target="_blank" rel="noopener" href="https://openreview.net/pdf?id=XobPpcN4yZ">Paper</a>]
</p>
</div>


<div class="row">
<p>[26] <b>Bridging Evolutionary Algorithms and Reinforcement Learning: A Comprehensive Survey
</b><br />
Pengyi Li, Jianye Hao, <u>Hongyao Tang</u>, Xian Fu, Yan Zheng, Ke Tang<br />
<i>IEEE Transactions on Evolutionary Computation (TEC) 2024</I>
 | [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2401.11963">Paper</a>]
</p>
</div>


<div class="row">
<p>[25] <b>Designing Biological Sequences without Prior Knowledge using Evolutionary Reinforcement Learning</b><br />
Xi Zeng, Xiaotian Hao, <u>Hongyao Tang</u>, Zhentai Tang, Shaoqing Jiao, Dazhi Lu, Jiajie Peng<br />
<i>AAAI 2024</i>
 | [<a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/27792">Paper</a>]
</p>
</div>


<h3 style="color:blue">2023</h3>

<div class="row">
<p>[24] <b>Reining Generalization in Offline Reinforcement Learning via Representation Distinction</b><br />
Yi Ma, <u>Hongyao Tang</u> (Corresponding Author), Dong Li, Zhaopeng Meng<br />
<i>NeurIPS 2023</I>
 | [<a target="_blank" rel="noopener" href="https://openreview.net/forum?id=mVywRIDNIl">Paper</a>]
</p>
</div>

<div class="row">
<p>[23] <b>Boosting Off-policy RL with Policy Representation and Policy-extended Value Function Approximator</b><br />
Min Zhang, Jianye Hao, <u>Hongyao Tang</u>, Yan Zheng<br />
<i>ICML 2023 Workshop on Frontiers4LCD</I>
 | [<a target="_blank" rel="noopener" href="https://openreview.net/forum?id=e4alNaUqyf">Paper</a>]
</p>
</div>


<div class="row">
<p>[22] <b>RACE: Improve Multi-Agent Reinforcement Learning with Representation Asymmetry and Collaborative Evolution</b><br />
Pengyi Li, Jianye Hao, <u>Hongyao Tang</u>, Yan Zheng, Xian Fu<br />
<i>ICML 2023</I>
 | [<a target="_blank" rel="noopener" href="https://openreview.net/forum?id=nHCfIQu2tV">Paper</a>]
</p>
</div>



<div class="row">
<p>[21] <b>ERL-Re^2: Efficient Evolutionary Reinforcement Learning with Shared State Representation and Individual Policy Representation</b><br />
Jianye Hao, Pengyi Li, <u>Hongyao Tang</u>, Yan Zheng, Xian Fu, Zhaopeng Meng<br />
<i>ICLR 2023 & DRL Workshop, NeurIPS 2022</I>
 | [<a target="_blank" rel="noopener" href="https://openreview.net/forum?id=FYZCHEtt6H0">Paper</a>]
[<a target="_blank" rel="noopener" href="https://github.com/yeshenpy/ERL-Re2">Code</a>]
</p>
</div>


<div class="row">
<p>[20] <b>Exploration in Deep Reinforcement Learning: From Single-Agent to Multi-Agent Domain</b><br />
Jianye Hao, Tianpei Yang, <u>Hongyao Tang</u>, Chenjia Bai, Jinyi Liu, Zhaopeng Meng, Peng Liu<br />
<i>IEEE Transactions on Neural Networks and Learning Systems (Accepted in 2023 Jan)</I>
 | [<a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/10021988">Paper</a>]
</p>
</div>



<h3 style="color:blue">2022</h3>


<div class="row">
<p>[19] <b>Towards A Unified Policy Abstraction Theory and Representation Learning Approach in Markov Decision Processes</b><br />
Min Zhang*, <u>Hongyao Tang</u>*, Jianye Hao, Yan Zheng<br />
<i>DRL Workshop, NeurIPS 2022</I>
 | [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2209.07696.pdf">Paper</a>]
</p>
</div>

<div class="row">
<p>[18] <b>PMIC: Improving Multi-Agent Reinforcement Learning with Progressive Mutual Information Collaboration</b><br />
Pengyi Li, <u>Hongyao Tang</u>, Tianpei Yang, Xiaotian Hao, Tong Sang, Yan Zheng, Jianye Hao, Matthew E. Taylor, Wenyuan Tao, Zhen Wang<br />
<i>ICML 2022</i>
 | [<a target="_blank" rel="noopener" href="https://proceedings.mlr.press/v162/li22s/li22s.pdf">Paper</a>]
[<a target="_blank" rel="noopener" href="https://github.com/yeshenpy/PMIC">Code</a>]
</p>
</div>

<div class="row">
<p>[17] <b>PAnDR: Fast Adaptation to New Environments from Offline Experiences via Decoupling Policy and Environment Representations</b><br />
Tong Sang*, <u>Hongyao Tang</u>*, Yi Ma, Jianye Hao, Yan Zheng, Zhaopeng Meng, Boyan Li, Zhen Wang<br />
<i>IJCAI 2022</i>
 | [<a target="_blank" rel="noopener" href="https://www.ijcai.org/proceedings/2022/0474.pdf">Paper</a>]
</p>
</div>

<div class="row">
<p>[16] <b>HyAR: Addressing Discrete-Continuous Action Reinforcement Learning via Hybrid Action Representation</b><br />
Boyan Li*, <u>Hongyao Tang</u>*, Yan Zheng, Jianye Hao, Pengyi Li, Zhen Wang, Zhaopeng Meng, Li Wang<br />
<i>ICLR 2022 & NeurIPS 2021 DRL Workshop Contributed Talk</I>
 | [<a target="_blank" rel="noopener" href="https://openreview.net/pdf?id=64trBbOhdGU">Paper</a>]
</p>
</div>

<div class="row">
<p>[15] <b>What about Inputting Policy in Value Function: Policy Representation and Policy-Extended Value Function Approximator</b><br />
<u>Hongyao Tang</u>, Zhaopeng Meng, Jianye Hao, Chen Chen, Daniel Graves, Dong Li, Changmin Yu, Hangyu Mao, Wulong Liu, Yaodong Yang, Wenyuan Tao, Li Wang<br />
<i>AAAI 2022 Oral Presentation (< 5%) & NeurIPS 2020 DRL Workshop</i>
 | [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2010.09536.pdf">Paper</a>]
</p>
</div>


<h3 style="color:blue">2021</h3>

<div class="row">
<p>[14] <b>An Efficient Transfer Learning Framework for Multiagent Reinforcement Learning</b><br />
Tianpei Yang*, Weixun Wang*, <u>Hongyao Tang</u>*, Jianye Hao, Zhaopeng Meng, Hangyu Mao, Dong Li, Wulong Liu, Yingfeng Chen, Yujing Hu, Changjie Fan, Chengwei Zhang<br />
<i>NeurIPS 2021</i>
 | [<a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper/2021/file/8d9a6e908ed2b731fb96151d9bb94d49-Paper.pdf">Paper</a>]
</p>
</div>


<div class="row">
<p>[13] <b>Foresee then Evaluate: Decomposing Value Estimation with Latent Future Prediction</b><br />
<u>Hongyao Tang</u>, Zhaopeng Meng, Guangyong Chen, Pengfei Chen, Chen Chen, Yaodong Yang, Luo Zhang, Wulong Liu, Jianye Hao<br />
<i>AAAI 2021</i>
 | [<a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/17182/16989">Paper</a>]
</p>
</div>



<div class="row">
<p>[12] <b>Towards Effective Context for Meta-Reinforcement Learning: an Approach based on Contrastive Learning</b><br />
Haotian Fu, <u>Hongyao Tang</u>, Jianye Hao, Chen Chen, Xidong Feng, Dong Li, Wulong Liu<br />
<i>AAAI 2021 & NeurIPS 2020 DRL Workshop</I>
 | [<a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/16914/16721">Paper</a>]
</p>
</div>


<div class="row">
<p>[11] <b>Addressing Action Oscillations through Learning Policy Inertia</b><br />
Chen Chen*, <u>Hongyao Tang</u>*, Jianye Hao, Wulong Liu, Zhaopeng Meng<br />
<i>AAAI 2021</i>
 | [<a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/16864/16671">Paper</a>]
</p>
</div>





<div class="row">
<p>[10] <b>Uncertainty-Aware Low-Rank Q-Matrix Estimation for Deep Reinforcement Learning</b><br />
Tong Sang, <u>Hongyao Tang</u>, Jianye Hao, Yan Zheng, Zhaopeng Meng<br />
<i>DAI 2021</I>
 | [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2111.10103">Paper</a>]
</p>
</div>

<div class="row">
<p>[9] <b>ED2: An Environment Dynamics Decomposition Framework for World Model Construction</b><br />
Cong Wang, Tianpei Yang, Jianye Hao, Yan Zheng, <u>Hongyao Tang</u>, Fazl Barez, Jinyi Liu, Jiajie Peng, Haiyin Piao, Zhixiao Sun<br />
<i>arXiv preprint (2021)</I>
 | [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2112.02817">Paper</a>]
</p>
</div>



<h3 style="color:blue">2020</h3>


<div class="row">
<p>[8] <b>Q-value Path Decomposition for Deep Multiagent Reinforcement Learning</b><br />
Yaodong Yang, Jianye Hao, Guangyong Chen, <u>Hongyao Tang</u>, Yingfeng Chen, Yujing Hu, Changjie Fan, Zhongyu Wei<br />
<i>ICML 2020</I>
 | [<a target="_blank" rel="noopener" href="http://proceedings.mlr.press/v119/yang20d/yang20d.pdf">Paper</a>]
</p>
</div>

<div class="row">
<p>[7] <b>Qatten: A General Framework for Cooperative Multiagent Reinforcement Learning</b><br />
Yaodong Yang, Jianye Hao, Ben Liao, Kun Shao, Guangyong Chen, Wulong Liu, <u>Hongyao Tang</u><br />
<i>arXiv preprint (2020)</I>
 | [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2002.03939.pdf">Paper</a>]
</p>
</div>

<div class="row">
<p>[6] <b>KoGuN: Accelerating Deep Reinforcement Learning via Integrating Human Suboptimal Knowledge</b><br />
Peng Zhang, Jianye Hao, Weixun Wang, <u>Hongyao Tang</u>, Yi Ma, Yihai Duan, Yan Zheng<br />
<i>IJCAI 2020</I>
 | [<a target="_blank" rel="noopener" href="https://www.ijcai.org/proceedings/2020/0317.pdf">Paper</a>]
</p>
</div>


<div class="row">
<p>[5] <b>MGHRL: Meta Goal-Generation for Hierarchical Reinforcement Learning</b><br />
Haotian Fu, <u>Hongyao Tang</u>, Jianye Hao, Wulong Liu, Chen Chen<br />
<i>DAI 2020</I>
 | [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1909.13607">Paper</a>]
</p>
</div>

<div class="row">
<p>[4] <b>Mastering Basketball With Deep Reinforcement Learning: An Integrated Curriculum Training Approach</b><br />
Hangtian Jia, Chunxu Ren, Yujing Hu, Yingfeng Chen, Tangjie Lv, Changjie Fan, <u>Hongyao Tang</u>, Jianye Hao<br />
<i>AAMAS 2020 Extended Abstract</I>
 | [<a target="_blank" rel="noopener" href="https://dl.acm.org/doi/10.5555/3398761.3399011">Paper</a>]
</p>
</div>



<h3 style="color:blue">2019 and Before</h3>

<div class="row">
<p>[3] <b>Hierarchical Deep Multiagent Reinforcement Learning with Temporal Abstraction</b><br />
<u>Hongyao Tang</u>, Jianye Hao, Tangjie Lv, Yingfeng Chen, Zongzhang Zhang, Hangtian Jia, Chunxu Ren, Yan Zheng, Changjie Fan, Li Wang<br />
<i>arXiv preprint (2019)</I>
 | [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1809.09332">Paper</a>]
</p>
</div>

<div class="row">
<p>[2] <b>Deep Multi-Agent Reinforcement Learning with Discrete-Continuous Hybrid Action Spaces</b><br />
Haotian Fu, <u>Hongyao Tang</u>, Jianye Hao, Zihan Lei, Yingfeng Chen, Changjie Fan<br />
<i>IJCAI 2019</I>
 | [<a target="_blank" rel="noopener" href="https://www.ijcai.org/proceedings/2019/0323.pdf">Paper</a>]
</p>
</div>

<div class="row">
<p>[1] <b>An Optimal Rewiring Strategy for Cooperative Multiagent Social Learning</b><br />
<u>Hongyao Tang</u>, Jianye Hao, Li Wang, Tim Baarslag, Zan Wang<br />
<i>AAAI 2019 Student Abstract Finalist & AAMAS 2019 Extended Abstract</I>
 | [<a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/5161/5034">Paper</a>]
</p>
</div>








          <div class="row mt-2">
  
    <div class="eight columns">
      <p id="madewith">Updated by Hongyao Tang, Dec 2024.
    </div>

    <!-- Sepcial thanks to https://simpleicons.org/ for the icons -->
    <div class="four columns mb-3 posisi" >
      
      <a class="ml-0 footer-link icon" href="https://github.com/bluecontra" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="GitHub">
        <svg class="github svg-hov" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
      </a>
      

      

      
      <a class="ml-0 footer-link icon" href="https://twitter.com/tanghyyy" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="Twitter">
        <svg class="twitter svg-hov" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Twitter</title><path d="M23.954 4.569c-.885.389-1.83.654-2.825.775 1.014-.611 1.794-1.574 2.163-2.723-.951.555-2.005.959-3.127 1.184-.896-.959-2.173-1.559-3.591-1.559-2.717 0-4.92 2.203-4.92 4.917 0 .39.045.765.127 1.124C7.691 8.094 4.066 6.13 1.64 3.161c-.427.722-.666 1.561-.666 2.475 0 1.71.87 3.213 2.188 4.096-.807-.026-1.566-.248-2.228-.616v.061c0 2.385 1.693 4.374 3.946 4.827-.413.111-.849.171-1.296.171-.314 0-.615-.03-.916-.086.631 1.953 2.445 3.377 4.604 3.417-1.68 1.319-3.809 2.105-6.102 2.105-.39 0-.779-.023-1.17-.067 2.189 1.394 4.768 2.209 7.557 2.209 9.054 0 13.999-7.496 13.999-13.986 0-.209 0-.42-.015-.63.961-.689 1.8-1.56 2.46-2.548l-.047-.02z"/></svg>
      </a>
      

      

    </div>
  
</div>

        </div>
      </div>

    </div>

  </div>
  <script src="/js/nanobar.min.js"></script>
  <script>
    var options = {
      classname: 'nanobar',
      id: 'myNanobar'
    };
    var nanobar = new Nanobar(options);
    nanobar.go(30);
    nanobar.go(76);
    nanobar.go(100);
  </script>

</body>

</html>
